{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CursoSpakPlatzi.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/dvlpana/SparkPlatzi/blob/main/CursoSpakPlatzi.ipynb",
      "authorship_tag": "ABX9TyMrcWnM2+2ESDk71mTa2gmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvlpana/SparkPlatzi/blob/main/CursoSpakPlatzi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x01L4jCsGp6",
        "outputId": "0be4711f-f9f9-4b2d-876e-2dc82acef5f9"
      },
      "source": [
        "#!apt-get install  openjdk-8-jdk-headless -qq > /dev/null\n",
        "!ad-apt-repository ppa:openjdk-r/ppa\n",
        "!apt-get update && sudo apt-get upgrade -y\n",
        "!apt-get -y install openjdk-8-jre\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ad-apt-repository: command not found\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 3s (86.8 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2 linux-headers-generic\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-8-jre is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6C34lrbni5i"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0IepqTMSyK8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A8DcYUj8dVg"
      },
      "source": [
        "import time\n",
        "print(\"Sleeping\")\n",
        "time.sleep(30) # sleep for a while; interrupt me!\n",
        "print(\"Done Sleeping\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0l_jN9L9HvI"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IRyJndaWzdw"
      },
      "source": [
        "!head -n 15 /content/sample_data/files_curso_spark/data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr97U3gBXYdY"
      },
      "source": [
        "!spark-submit /content/sample_data/files_curso_spark/codeExample.py /content/sample_data/files_curso_spark/data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUSPTj3VXz--"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FBagAFFsrDo"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlTGhbtasx_N"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eOv_h_3oyeJ"
      },
      "source": [
        "archivo = './sample_data/files_curso_spark/data.csv'\n",
        "df_spark = spark.read.csv(archivo, inferSchema=True, header=True)\n",
        "\n",
        "# imprimir tipo de archivo\n",
        "print(type(df_spark))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QegavfxLzA5p"
      },
      "source": [
        "¿Nombre de las Columnas de dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCyMh-Fbp55r"
      },
      "source": [
        "df_spark.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YseA6qsgzq4B"
      },
      "source": [
        "Estructura del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv_UqUmoprF2"
      },
      "source": [
        "df_spark.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inRLRbSVx45Y"
      },
      "source": [
        "Ver los primeros 20 registros del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTNNeZUQwNYj"
      },
      "source": [
        "df_spark.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWAoYmp1xvBT"
      },
      "source": [
        "Descricipcion Estadistica del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dbIyYnjwZxa"
      },
      "source": [
        "df_spark.describe().toPandas().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF80Ws8O0FC9"
      },
      "source": [
        "Descripcion estadistica de una sola columna (‘median_house_value’)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPVS0UGM0NSa"
      },
      "source": [
        "df_spark.describe(['color']).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2y-SQot6NVx"
      },
      "source": [
        "## 8 Transformaciones y Acciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKB7p-fT6TS5"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Learning_Spark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "lines = sc.textFile(\"spark-2.4.4-bin-hadoop2.7/README.md\")\n",
        "sc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdISl8cLK4wp"
      },
      "source": [
        "path = '/content/sample_data/files_curso_spark/'\n",
        "equiposOlimpicosRDD = sc.textFile(path+'paises.csv') \\\n",
        ".map(lambda line: line.split(\",\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vki2aIzXI6k"
      },
      "source": [
        "# Muestra la data con take , evita utilizar collect()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGs2ekBGW3Hh"
      },
      "source": [
        "equiposOlimpicosRDD.take(10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLN2OCx4Ppoy"
      },
      "source": [
        "9 Acciones de modificacion sobre RDDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg5wkmLuPs3f"
      },
      "source": [
        "##Contar cuantas siglas tenemos\n",
        "equiposOlimpicosRDD.map(lambda x: (x[2])).distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmYibg7fcoZ"
      },
      "source": [
        "##Agrupación a partir de siglas y obtener cantidad de equipos por país\n",
        "equiposOlimpicosRDD \\\n",
        ".map(lambda x: (x[2], x[1])) \\\n",
        ".groupByKey() \\\n",
        ".mapValues(len).take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9nGx_goaCn"
      },
      "source": [
        "rdd1 = sc.parallelize([1,2,3])\n",
        "type(rdd1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLWeOERyg_hv"
      },
      "source": [
        "##Agrupación a partir de siglas y obtener cantidad de equipos por país\n",
        "equiposOlimpicosRDD \\\n",
        ".map(lambda x: (x[2], x[1])) \\\n",
        ".groupByKey() \\\n",
        ".mapValues(list).take(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AegDkoayhr74"
      },
      "source": [
        "##Obtener los datos sólo de un país o contenido con filter()\n",
        "equiposArgentinos = equiposOlimpicosRDD.filter(lambda x: \"ARG\" in x)\n",
        "equiposArgentinos.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4N1fVpk0DI"
      },
      "source": [
        "## Cuenta todos los valores, nada recomendable para datos extensos\n",
        "equiposOlimpicosRDD.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUp0-dfNlYc-"
      },
      "source": [
        "##Cuenta  hasta el tiempo aproximado\n",
        "equiposOlimpicosRDD.countApprox(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCl25Rqzra89"
      },
      "source": [
        "10 Acciones de conteo sobre RDDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-eyUOHzrgFk"
      },
      "source": [
        "## importamos ambos\n",
        "deportistaOlimpicoRDD = sc.textFile(path+'deportista.csv') \\\n",
        ".map(lambda line: line.split(\",\"))\n",
        "\n",
        "deportistaOlimpicoRDD2 = sc.textFile(path+'deportista2.csv') \\\n",
        ".map(lambda line: line.split(\",\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU2-H91BuIw1"
      },
      "source": [
        "## Unimos los RDD con union(). Spark solo tiene esta operacion\n",
        "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union(deportistaOlimpicoRDD2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPuyCVVxBev"
      },
      "source": [
        "deportistaOlimpicoRDD.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kp0mWFoxJIs"
      },
      "source": [
        "##Ver contenido en equipos olimpicos\n",
        "equiposOlimpicosRDD.top(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlnHHbABx_M4"
      },
      "source": [
        "deportistaOlimpicoRDD.top(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5laQ8zycysjk"
      },
      "source": [
        "# seleccionamos las comumnas ID para hacer un join\n",
        "deportistaOlimpicoRDD \\\n",
        ".map(lambda deportista: [deportista[-1],deportista[:-1]]) \\\n",
        ".join(equiposOlimpicosRDD.map(lambda equipo: [equipo[0], equipo [2]])) \\\n",
        ".take(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sLjUH4S1WGu"
      },
      "source": [
        "# utilizamos takeSample (repetidos, muestra, semilla)\n",
        "deportistaOlimpicoRDD \\\n",
        ".map(lambda deportista: [deportista[-1],deportista[:-1]]) \\\n",
        ".join(equiposOlimpicosRDD.map(lambda equipo: [equipo[0], equipo [2]])) \\\n",
        ".takeSample(False,6,25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avC4Gx4T2moS"
      },
      "source": [
        "resultado = sc.textFile(path+'resultados.csv') \\\n",
        ".map(lambda line: line.split(\",\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kRslCff3IEM"
      },
      "source": [
        "resultadoGanador = resultado.filter(lambda w: 'NA' not in w[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBKPyOBO3u8u"
      },
      "source": [
        "resultadoGanador.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyUlDYyfJlmi"
      },
      "source": [
        "##Reto Hacer un join con equipos y deportista para obtener valores importantes\n",
        "deportistaOlimpicoRDD \\\n",
        ".map(lambda deportista: [deportista[-1],deportista[:-1]]) \\\n",
        ".join(equiposOlimpicosRDD.map(lambda equipo: [equipo[0], equipo [2]])) \\\n",
        ".join(resultadoGanador.map(lambda resultado: [resultado[2], resultado [1]])) \\\n",
        ".takeSample(False, 6, 25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrPC-D7VaFH"
      },
      "source": [
        "Clase 11 Solucion reto deportistas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asCzgxzdVcbZ"
      },
      "source": [
        "#esta clase muestra la solucion del profesor al reto.\n",
        "deportistaPaises = deportistaOlimpicoRDD \\\n",
        "    .map(lambda l: [l[-1], l[:-1]]) \\\n",
        "    .join(equiposOlimpicosRDD.map(lambda x: [x[0], x[2]]))\n",
        "\n",
        "deportistaPaises.join(resultadoGanador).take(6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwheJjFPXKs1"
      },
      "source": [
        "#Clase 12 Operaciones Numéricas\n",
        "##En esta clase hacemos el encoding de los valores de las medallas y obtenemos los puntos que tiene cada país.\n",
        "Acciones de Conteo sobre RDD\n",
        "\n",
        "```\n",
        "# Tiene formato de código\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y7J2SFBXNc9"
      },
      "source": [
        "!ls ./sample_data/files_curso_spark/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYnJMgeabq6t"
      },
      "source": [
        "#Almacenamos el puntaje por medalla\n",
        "valoresMedallas = {'Gold'  :7,\n",
        "                   'Silver':5,\n",
        "                   'Bronze':4}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwqgiiJOeXuk"
      },
      "source": [
        "paisesMedallas = deportistaPaises.join(resultadoGanador)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydch0DnMgHkE"
      },
      "source": [
        "paisesMedallas = paisesMedallas \\\n",
        "    .map(lambda x: (x[1][0][-1], valoresMedallas[x[1][1] ] ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj2WeASlm4kM"
      },
      "source": [
        "paisesMedallas.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It736Z_RnllI"
      },
      "source": [
        "from operator import add\n",
        "\n",
        "conclusion = paisesMedallas.reduceByKey((add)) \\\n",
        "    .sortBy(lambda x:x[1], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpzmlQJonqRz"
      },
      "source": [
        "conclusion.take(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ra7hnmroWq"
      },
      "source": [
        "Clase 13 Creación de DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbsRERdErpoT"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField\n",
        "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
        "from pyspark.sql.types import Row\n",
        "\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td9nqG_i3tp2"
      },
      "source": [
        "#spark = SparkContext(master='local', appName=\"DataFrames\")\n",
        "sqlContext = SQLContext(spark)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QImgf4njIZwQ"
      },
      "source": [
        "!ls ./sample_data/files_curso_spark/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9upLVKRwIuz3"
      },
      "source": [
        "!head -n 10 ./sample_data/files_curso_spark/juegos.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzgLiegELTBj"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRYWEk7FLqpr"
      },
      "source": [
        "# Paso 1 crear un dataFrame es crearun Schema como una base de datos\n",
        "path = '/content/sample_data/files_curso_spark/'\n",
        "juegoSchema = StructType([\n",
        "     StructField('juego_id', IntegerType(), False),\n",
        "     StructField('anio', StringType(), False),\n",
        "     StructField('temporada', StringType(), False),\n",
        "     StructField('ciudad', StringType(), False),\n",
        "    ])\n",
        "# Paso 2 Crea Data Frame con la Lectura del Schema \n",
        "juegoDF = sqlContext.read.schema(juegoSchema) \\\n",
        "          .option('header', 'true').csv(path+'resultados.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZCWHucEkunr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgEDfT2iRTz5"
      },
      "source": [
        "juegoDF.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwyl38l5oyLx"
      },
      "source": [
        "Clase 14 Inferencia de tipos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsfk60-vpAPb"
      },
      "source": [
        "deportistaOlimpicoRDD.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh3ppCGJrAOz"
      },
      "source": [
        "# Retiramos encabezados\n",
        "def eliminarEncabezado(indice, iterador):\n",
        "  return iter(list(iterador)[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBzTrwqUrqqr"
      },
      "source": [
        "deportistaOlimpicoRDD = deportistaOlimpicoRDD.\\\n",
        "mapPartitionsWithIndex(eliminarEncabezado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMp_waadsExR"
      },
      "source": [
        "deportistaOlimpicoRDD.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwnWOSMmvFuE"
      },
      "source": [
        "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l: (\n",
        "    int(l[0]),\n",
        "    l[1],\n",
        "    int(l[2]),\n",
        "    int(l[3]),\n",
        "    int(l[4]),\n",
        "    float(l[5]),\n",
        "    int(l[6]),\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYrX_lFwiYd"
      },
      "source": [
        "deportistaOlimpicoRDD.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtoOxtRwo5U"
      },
      "source": [
        "schema_deportistaOlimpico = StructType([\n",
        "    StructField('deportista_id', IntegerType(),False),\n",
        "    StructField('nombre', StringType(),False),\n",
        "    StructField('genero', IntegerType(),False),\n",
        "    StructField('edad', IntegerType(),False),\n",
        "    StructField('altura', IntegerType(),False),\n",
        "    StructField('peso', FloatType(),False),\n",
        "    StructField('equipo_id', IntegerType(),False)\n",
        "]    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22C3YmVa25Xu"
      },
      "source": [
        "deportistaDF =  sqlContext.createDataFrame(deportistaOlimpicoRDD, schema_deportistaOlimpico)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNGWJngd3Q4u"
      },
      "source": [
        "deportistaDF.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8-zkBET4kuo"
      },
      "source": [
        "Retos crear los demas DataFrames testantes a partir de los RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ43oT-L4uez"
      },
      "source": [
        "# Países  equipos, sc???\n",
        "paisesRDD = sc.textFile(path+'paises.csv') \\\n",
        ".map(lambda line: line.split(\",\")) \\\n",
        ".mapPartitionsWithIndex(eliminarEncabezado) \\\n",
        ".map(lambda l:(\n",
        "    int(l[0]),\n",
        "    l[1],\n",
        "    l[2]\n",
        "))\n",
        "\n",
        "schema = StructType([\n",
        "    StructField('pais_id', IntegerType(),False),\n",
        "    StructField('equipo', StringType(),False),\n",
        "    StructField('sigla', StringType(),False)\n",
        "\n",
        "]    \n",
        ")\n",
        "\n",
        "paisesDF =  sqlContext.createDataFrame(paisesRDD, schema)\n",
        "paisesDF.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_M-wQlRGS6J"
      },
      "source": [
        "resultados_schema = StructType([\n",
        "    StructField(\"resultado_id\", IntegerType(), False),\n",
        "    StructField(\"medalla\", StringType(), False),\n",
        "    StructField(\"deportista_id\", IntegerType(), False),\n",
        "    StructField(\"juego_id\", IntegerType(), False),\n",
        "    StructField(\"evento_id\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "resultadosDF = sqlContext.read.format(\"csv\").\\\n",
        "            option(\"header\", True).\\\n",
        "            schema(resultados_schema).\\\n",
        "            load(path+\"resultados.csv\")\n",
        "\n",
        "resultadosDF.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hABhDOAR8y2"
      },
      "source": [
        "evento_schema = StructType([\n",
        "    StructField(\"evento_id\", IntegerType(), False),\n",
        "    StructField(\"evento\", StringType(), False), \n",
        "    StructField(\"deporte_id\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "eventoDF = sqlContext.read.format(\"csv\").\\\n",
        "        option(\"header\", True).\\\n",
        "        schema(evento_schema).\\\n",
        "        load(path+\"evento.csv\")\n",
        "\n",
        "eventoDF.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgxxeriTVb7"
      },
      "source": [
        "deporte_schema = StructType([\n",
        "          StructField(\"deporte_id\",IntegerType(),False),\n",
        "          StructField(\"deporte\", StringType(),False)\n",
        "])\n",
        "\n",
        "deporteDF = sqlContext.read.format(\"csv\").\\\n",
        "        option(\"header\", True).\\\n",
        "        schema(deporte_schema).\\\n",
        "        load(path+\"deporte.csv\")\n",
        "\n",
        "deporteDF.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj5HzqsiVNQN"
      },
      "source": [
        "# juegos\n",
        "\n",
        "juegos_schema = StructType([\n",
        "    StructField('nombre_juego', StringType(),False),\n",
        "    StructField('annio', IntegerType(),False),\n",
        "    StructField('temporada', StringType(),False),\n",
        "    StructField('ciudad', StringType(),False)\n",
        "]    \n",
        ")\n",
        "\n",
        "juegosDF = sqlContext.read.format(\"csv\").\\\n",
        "        option(\"header\", True).\\\n",
        "        schema(juegos_schema).\\\n",
        "        load(path+\"juegos.csv\")\n",
        "\n",
        "juegosDF.show(4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrqw0mUBaHzm"
      },
      "source": [
        " Clase 15 Operaciones sobre DF.\n",
        "En esta clase aprendemos como obtener el schema de un DataFrame, a renombrar columnas y select()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXQhrk5XaZUq"
      },
      "source": [
        "# Ver el esquema\n",
        "deporteDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGMiJqEfbOEB"
      },
      "source": [
        "# Ver el esquema\n",
        "deportistaDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXLs4CfErSOo"
      },
      "source": [
        "#Renombrar columnas\n",
        "deportistaOlimpicoDF = deportistaDF \\\n",
        ".withColumnRenamed(\"genero\", 'sexo') \\\n",
        ".drop('altura')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkLT9XCathZV"
      },
      "source": [
        "deportistaOlimpicoDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ5AaIy1wKQZ"
      },
      "source": [
        "# Usando el rey SELECT\n",
        "from pyspark.sql.functions import *\n",
        "deportistaOlimpicoDF = deportistaOlimpicoDF.select(\"deportista_id\",\"nombre\",\n",
        " col(\"edad\").alias(\"edadAlJugar\"),\n",
        " \"equipo_id\"\n",
        " )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPwN93J4hn6"
      },
      "source": [
        "deportistaOlimpicoDF.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zx5smR44x93"
      },
      "source": [
        "# Usando filter\n",
        "deportistaOlimpicoDF = deportistaOlimpicoDF.filter(\n",
        "    (deportistaOlimpicoDF.edadAlJugar != 0)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj-b_dsf5ZEk"
      },
      "source": [
        "deportistaOlimpicoDF.sort(\"edadAlJugar\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdvwHvUgE4qf"
      },
      "source": [
        "Clase 16 Agrupaciones y operaciones join sobre DF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtF9JSx9GdXw"
      },
      "source": [
        "#vizualizamos los esquemas de los DF\n",
        "deportistaOlimpicoDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFhIIjvvG3Ff"
      },
      "source": [
        "resultadosDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhT0h_ZHRUB"
      },
      "source": [
        "juegosDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc9ZZmkxHRiV"
      },
      "source": [
        "deporteDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6k4nKnDIt62"
      },
      "source": [
        "paisesDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk8yNbH_IuKc"
      },
      "source": [
        "#JOINS\n",
        "deportistaOlimpicoDF \\\n",
        ".join(\n",
        "    resultadosDF,\n",
        "    deportistaOlimpicoDF.deportista_id == resultadosDF.deportista_id,\n",
        "    \"left\"\n",
        ") \\\n",
        ".join(\n",
        "    juegoDF,\n",
        "    juegoDF.juego_id == resultadosDF.juego_id,\n",
        ") \\\n",
        ".join(\n",
        "    eventoDF,\n",
        "    eventoDF.evento_id == resultadosDF.evento_id,\n",
        "    \"left\"\n",
        ") \\\n",
        ".select(deportistaOlimpicoDF.nombre,\n",
        "        \"edadAlJugar\",\n",
        "        \"medalla\",\n",
        "        col(\"anio\").alias(\"annio de juego\"),\n",
        "        deportistaOlimpicoDF.nombre.alias(\"Nombre disciplina\")   \n",
        ").show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5M5q3AfIuYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcXINbRmIulu"
      },
      "source": [
        "#Reto hacer un JOIN con todas las medallas ganadoras\n",
        "#unidas con el país y el equipo al que pertenecen estas medallas\n",
        "resultadosDF \\\n",
        ".join(\n",
        "    deportistaOlimpicoDF,\n",
        "   resultadosDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
        "    \"left\"\n",
        ") \\\n",
        ".join(\n",
        "   paisesDF,\n",
        "    deportistaOlimpicoDF.equipo_id == paisesDF.pais_id ,\n",
        "    \"left\"\n",
        ") \\\n",
        ".select(\"medalla\",\n",
        "        paisesDF.equipo,\n",
        "       paisesDF.sigla\n",
        ") \\\n",
        ".where (resultadosDF.medalla != \"NA\").show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk6Sqwij5k5T"
      },
      "source": [
        "# Clase 17 Solucion reto joins\n",
        "resultadosDF.filter(resultadosDF.medalla != \"NA\") \\\n",
        ".join(\n",
        "    deportistaOlimpicoDF,\n",
        "     resultadosDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
        "     \"left\"     \n",
        ") \\\n",
        ".join(\n",
        "    paisesDF,\n",
        "     deportistaOlimpicoDF.equipo_id == paisesDF.pais_id,\n",
        "     \"left\"\n",
        ") \\\n",
        ".select(\"medalla\", paisesDF.equipo, paisesDF.sigla) \\\n",
        ".sort(col(\"sigla\").desc()) \\\n",
        ".show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ_Q2wLPk8Oy"
      },
      "source": [
        "#Clase 18 Funciones de agrupación\n",
        "#En esta clase revisamos cuales son las funciones de agrupación con que cuenta Spark."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRQnHK2eGRE3"
      },
      "source": [
        "evento_schema = StructType([\n",
        "    StructField('evento_id', IntegerType(),False),\n",
        "    StructField('nombre', StringType(),False),\n",
        "    StructField('deporte_id', IntegerType(),False)\n",
        "]    \n",
        ")\n",
        "\n",
        "deportesOlimpicosDF = sqlContext.read.format(\"csv\").\\\n",
        "        option(\"header\", True).\\\n",
        "        schema(evento_schema).\\\n",
        "        load(path+\"evento.csv\")\n",
        "\n",
        "deportesOlimpicosDF.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukrSbuuJkvGJ"
      },
      "source": [
        "#Clase 18 Funciones de agrupación\n",
        "medallistaXanio = deportistaOlimpicoDF \\\n",
        "   .join (\n",
        "       resultadosDF,\n",
        "       deportistaOlimpicoDF.deportista_id == resultadosDF.deportista_id,\n",
        "       \"left\"\n",
        "         )\\\n",
        "   .join(\n",
        "       juegoDF,\n",
        "       juegoDF.juego_id == resultadosDF.juego_id,\n",
        "       \"left\"\n",
        "        )\\\n",
        "   .join(\n",
        "     paisesDF,\n",
        "     deportistaOlimpicoDF.equipo_id == paisesDF.pais_id,\n",
        "     \"left\"\n",
        "        )\\\n",
        "     .join(\n",
        "         deportesOlimpicosDF,\n",
        "         deportesOlimpicosDF.evento_id == resultadosDF.evento_id,\n",
        "         \"left\"\n",
        "        )\\\n",
        "      .join(\n",
        "          deporteDF,\n",
        "          deportesOlimpicosDF.deporte_id == deporteDF.deporte_id,\n",
        "          \"left\"\n",
        "          )\\\n",
        "       .select(\n",
        "           \"sigla\",\n",
        "           \"anio\",\n",
        "           \"medalla\",\n",
        "           deportesOlimpicosDF.nombre.alias(\"Nombre subdisciplina\"),\n",
        "           deporteDF.deporte.alias(\"Nombre disciplina\"),\n",
        "           deportistaOlimpicoDF.nombre\n",
        "       )            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HcaQqAvPHHU"
      },
      "source": [
        "medallistaXanio.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3ivTb8Qs-m"
      },
      "source": [
        "#Descartamos deportistas sin medalla\n",
        "medallistaXAnio2 = medallistaXanio.filter(resultadosDF.medalla != \"NA\")\\\n",
        "                                  .sort(\"anio\")\\\n",
        "                                  .groupBy(\"sigla\",\"anio\",\"nombre subdisciplina\")\\\n",
        "                                  .count() \n",
        "medallistaXAnio2.show()                                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCa3I3msTSj-"
      },
      "source": [
        "medallistaXAnio2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO9zrXU_Vuel"
      },
      "source": [
        "# .agg o agragate es la forma recomendada pos la documentación\n",
        "medallistaXAnio2.groupBy(\"Sigla\",\"anio\")\\\n",
        "    .agg(sum(\"count\").alias(\"Total de medallas\"), \\\n",
        "     avg(\"count\").alias(\"Medallas promedio\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgHs42wwoDVP"
      },
      "source": [
        "Clase 19 SQL\n",
        "\n",
        "En esta clase registramos DataFrames como si fueran SQL y veremos las diferencias entre ejecutar SQL como si fuera Spark y la forma nativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqYmTU83oGFs"
      },
      "source": [
        "# registramos DataAframes como tables SQL\n",
        "resultadosDF.registerTempTable(\"resultado\")\n",
        "deportistaOlimpicoDF.registerTempTable(\"deportista\")\n",
        "paisesDF.registerTempTable(\"paises\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlryZzT2py82"
      },
      "source": [
        "sqlContext.sql(\"SELECT * FROM deportista\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAQOClTyq4mL"
      },
      "source": [
        "#En términos generales el script de SQL es mas rápido que utilizar la sintaxis de Spark, \n",
        "#sin embargo el trade-off es que es mas costoso computacionalmente, esto lo podemos \n",
        "#observar en el gráfico de SparkUI, donde Catalyst nos ayuda.\n",
        "sqlContext.sql(\"\"\"\n",
        "               SELECT medalla, equipo, sigla FROM resultado as r\n",
        "               JOIN deportista as d\n",
        "               ON r.deportista_id = d.deportista_id\n",
        "               JOIN paises as p\n",
        "               ON p.id_ = d.equipo_id\n",
        "               WHERE medalla <> \"NA\"\n",
        "               ORDER BY sigla DESC\n",
        "              \"\"\").show(15)\n",
        "#Recomendación, si vas a hacer cruces, joins o funciones de agregacion es mejor usar \n",
        "#el poder de SPARK y sus funciones nativas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hllMgplYtwYP"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg27ksdzwz6E"
      },
      "source": [
        "!ls ./sample_data/files_curso_spark/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TULTfQSxf66"
      },
      "source": [
        "!head -n 5 ./sample_data/files_curso_spark/deportista.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqoTnlrWZV7u"
      },
      "source": [
        "#Clase 21 UDF\n",
        "\n",
        "#Una de las ventajas de las UDF es registrarlas para que #trabajen nativamente y ademas poder usarlas con las #consultas de SQL estándar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauPvVlYZr6A"
      },
      "source": [
        "DeportistaError_schema = StructType([\n",
        "    StructField(\"deportista_id\", StringType(), False),\n",
        "    StructField(\"nombre\", StringType(), False),\n",
        "    StructField(\"genero\", StringType(), False),\n",
        "    StructField(\"edad\", StringType(), False),\n",
        "    StructField(\"altura\", StringType(), False), \n",
        "    StructField(\"peso\", StringType(), False),\n",
        "    StructField(\"equipo_id\", StringType(), False)\n",
        "])\n",
        "\n",
        "DeportistaErrorDF = sqlContext.read.format(\"csv\").\\\n",
        "            option(\"header\", True).\\\n",
        "            schema(DeportistaError_schema).\\\n",
        "            load(path+\"deportistaError.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}